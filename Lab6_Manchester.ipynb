{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf1cea-abe6-408a-b939-26536fd3f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**Total Images Used in Our Dataset** 70,000 (split 60,000 for training, 10,000 for testing)\n",
    "#**Number of Classes** 10 (digits from 0 to 9)\n",
    "#**Image Dimensions** 28×28 pixels, in grayscale\n",
    "#**Format** Each image is a single-channel 28×28 pixel matrix \n",
    "\n",
    "\n",
    "import sys\n",
    "#!{sys.executable} -m pip install matplotlib\n",
    "#!{sys.executable} -m pip install torchsummary\n",
    "#!{sys.executable} -m pip install scikit-learn seaborn\n",
    "\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "#define transformations \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize((0.1307,), (0.3081,))  #mean and Std for MNIST\n",
    "])\n",
    "\n",
    "#download and load the MNIST dataset\n",
    "train_dataset = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "#create DataLoaders for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "#print(\"MNIST dataset loaded successfully!\")\n",
    "#print(f\"Training set size: {len(train_dataset)} images\")\n",
    "#print(f\"Testing set size: {len(test_dataset)} images\")\n",
    "\n",
    "#Normalizing the MNIST dataset ensures that pixel values that starts normally at 0 to 255 are now scaled to a standard range!\n",
    "def show_processed_images(data_loader, num_images=9):\n",
    "    images, labels = next(iter(data_loader))  # Get a batch of images\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        img = images[i].squeeze().numpy()\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(f\"Label: {labels[i].item()}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Processed MNIST Images --> Cole M\", fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "show_processed_images(train_loader)\n",
    "\n",
    "\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        #convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # 28x28 -> 14x14\n",
    "        self.fc1 = nn.Linear(64 * 14 * 14, 128)  #fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 10)  #output layer (10 classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)  \n",
    "        #flatten for FC layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  #no activation, softmax applied during loss calculation\n",
    "        return x\n",
    "\n",
    "#instantiate model\n",
    "model = MNIST_CNN()\n",
    "print(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  #suitable for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  #adam optimizer\n",
    "summary(model, (1, 28, 28))\n",
    "\n",
    "num_epochs = 10  #10 epochs to start us off with\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  #reset gradients\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # backpropagation\n",
    "        optimizer.step()  #update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_acc.append(correct / total)\n",
    "\n",
    "    #evaluate on our test set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  #disable gradients for faster inference\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "    test_acc.append(correct / total)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {train_losses[-1]:.4f}, Acc: {train_acc[-1]*100:.2f}%, Val Loss: {test_losses[-1]:.4f}, Val Acc: {test_acc[-1]*100:.2f}%\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "\n",
    "# plot Training & Validation Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# plot Train, Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(test_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# sample Predictions vs. Actual Labels\n",
    "def show_predictions(model, data_loader, device, num_images=9):\n",
    "    model.eval()\n",
    "    images, labels = next(iter(data_loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        img = images[i].cpu().squeeze().numpy()\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(f\"Predicted: {predicted[i].item()}, Actual: {labels[i].item()}\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(model, test_loader, device)\n",
    "\n",
    "# confusion Matrix\n",
    "def plot_confusion_matrix(model, data_loader, device, class_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(model, test_loader, device, list(range(10)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0040fe74-2f42-4a65-a44c-16ad4b25def4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebcd181-c203-46f6-bfe1-f0001605ef08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
